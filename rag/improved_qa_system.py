import chromadb
import re
from chroma_store import get_client
from difflib import SequenceMatcher

client = get_client()
collection = client.get_or_create_collection(name="weather") 

def fuzzy_match_province(query, provinces, threshold=0.6):
    """‡∏´‡∏≤‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î"""
    best_match = None
    best_score = 0
    
    for province in provinces:
        # ‡∏•‡∏ö‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ "‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î" ‡πÅ‡∏•‡∏∞‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á
        clean_query = re.sub(r'‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î:?\s*', '', query).strip()
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢
        score = SequenceMatcher(None, clean_query.lower(), province.lower()).ratio()
        
        if score > best_score and score >= threshold:
            best_score = score
            best_match = province
    
    return best_match, best_score

def extract_province_from_query(query):
    """‡∏î‡∏∂‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏à‡∏≤‡∏Å query"""
    # ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏£‡∏∞‡∏ö‡∏∏‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î
    patterns = [
        r'‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î:?\s*([‡∏Å-‡πô\s]+?)(?:\s|$|‡πÄ‡∏õ‡πá‡∏ô|‡∏≠‡∏≤‡∏Å‡∏≤‡∏®|‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥|‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏∑‡πâ‡∏ô)',
        r'‡∏à\.?\s*([‡∏Å-‡πô\s]+?)(?:\s|$|‡πÄ‡∏õ‡πá‡∏ô|‡∏≠‡∏≤‡∏Å‡∏≤‡∏®|‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥|‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏∑‡πâ‡∏ô)',
        r'^([‡∏Å-‡πô]+?)(?:\s|$|‡πÄ‡∏õ‡πá‡∏ô|‡∏≠‡∏≤‡∏Å‡∏≤‡∏®|‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥|‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏∑‡πâ‡∏ô)',
        r'([‡∏Å-‡πô]+?)(?:‡∏≠‡∏≤‡∏Å‡∏≤‡∏®|‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£|‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥|‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏∑‡πâ‡∏ô)'
    ]
    
    for pattern in patterns:
        match = re.search(pattern, query)
        if match:
            return match.group(1).strip()
    
    return None

def hybrid_search(query, n_results=3):
    """‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏ö‡∏ö Hybrid: Exact + Semantic"""
    
    print(f"üîç ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤: '{query}'")
    
    # 1. ‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
    all_data = collection.get()
    provinces = list(set(meta['province'] for meta in all_data['metadatas']))
    
    # 2. ‡∏´‡∏≤‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏à‡∏≤‡∏Å query
    extracted_province = extract_province_from_query(query)
    print(f"üèõÔ∏è ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ó‡∏µ‡πà‡∏î‡∏∂‡∏á‡πÑ‡∏î‡πâ: {extracted_province}")
    
    # 3. Fuzzy matching ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ exact match
    target_province = None
    if extracted_province:
        if extracted_province in provinces:
            target_province = extracted_province
            print(f"‚úÖ ‡πÄ‡∏à‡∏≠‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô: {target_province}")
        else:
            fuzzy_province, score = fuzzy_match_province(extracted_province, provinces)
            if fuzzy_province:
                target_province = fuzzy_province
                print(f"üéØ Fuzzy match: {fuzzy_province} (‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô: {score:.2f})")
    
    # 4. ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    results = None
    
    if target_province:
        # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏ö‡∏ö exact match metadata ‡∏Å‡πà‡∏≠‡∏ô
        exact_results = collection.query(
            query_texts=[query],
            n_results=n_results,
            where={"province": target_province}
        )
        
        if exact_results['documents'][0]:
            print(f"üìç ‡πÄ‡∏à‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• exact match: {len(exact_results['documents'][0])} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
            results = exact_results
        else:
            print("‚ùå ‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• exact match")
    
    # 5. ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ exact match ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ semantic search
    if not results or not results['documents'][0]:
        print("üîÑ ‡πÉ‡∏ä‡πâ semantic search")
        semantic_results = collection.query(
            query_texts=[query],
            n_results=n_results * 2  # ‡πÄ‡∏≠‡∏≤‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏£‡∏≠‡∏á
        )
        
        # ‡∏Å‡∏£‡∏≠‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÉ‡∏´‡πâ‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô
        if target_province and semantic_results['documents'][0]:
            # ‡∏´‡∏≤‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á
            filtered_docs = []
            filtered_meta = []
            filtered_distances = []
            
            for i, (doc, meta, dist) in enumerate(zip(
                semantic_results['documents'][0],
                semantic_results['metadatas'][0],
                semantic_results.get('distances', [[]])[0]
            )):
                if meta['province'] == target_province:
                    filtered_docs.append(doc)
                    filtered_meta.append(meta)
                    filtered_distances.append(dist)
                    if len(filtered_docs) >= n_results:
                        break
            
            if filtered_docs:
                results = {
                    'documents': [filtered_docs],
                    'metadatas': [filtered_meta],
                    'distances': [filtered_distances]
                }
                print(f"üéØ ‡∏Å‡∏£‡∏≠‡∏á‡πÅ‡∏•‡πâ‡∏ß: {len(filtered_docs)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
        
        if not results or not results['documents'][0]:
            results = semantic_results
            # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
            if results['documents'][0]:
                results['documents'] = [results['documents'][0][:n_results]]
                if 'metadatas' in results:
                    results['metadatas'] = [results['metadatas'][0][:n_results]]
                if 'distances' in results:
                    results['distances'] = [results['distances'][0][:n_results]]
    
    return results, target_province

def ask(query):
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ñ‡∏≤‡∏°-‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÅ‡∏•‡πâ‡∏ß"""
    
    results, target_province = hybrid_search(query)
    
    if not results or not results['documents'][0]:
        print("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á")
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö
        all_data = collection.get()
        provinces = sorted(set(meta['province'] for meta in all_data['metadatas']))
        print(f"\nüó∫Ô∏è ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö ({len(provinces)} ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î):")
        for i, province in enumerate(provinces, 1):
            print(f"   {i:2d}. {province}")
        return
    
    print(f"\n‚úÖ ‡∏û‡∏ö {len(results['documents'][0])} ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:")
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á
    distances = results.get('distances', [[]])[0]
    
    for i, doc in enumerate(results['documents'][0]):
        score_text = f" (‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô: {distances[i]:.3f})" if i < len(distances) else ""
        print(f"\nüîπ ‡∏ï‡∏≠‡∏ö {i+1}{score_text}:")
        print(doc)
        print("-" * 50)

def test_improved_system():
    """‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÅ‡∏•‡πâ‡∏ß"""
    print("üß™ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö QA ‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÅ‡∏•‡πâ‡∏ß")
    print("=" * 60)
    
    test_queries = [
        "‡∏ä‡∏•‡∏ö‡∏∏‡∏£‡∏µ",
        "‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ä‡∏•‡∏ö‡∏∏‡∏£‡∏µ", 
        "‡∏ä‡∏•‡∏ö‡∏∏‡∏£‡∏µ‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£",
        "‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥‡∏ä‡∏•‡∏ö‡∏∏‡∏£‡∏µ",
        "‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏Ø",
        "‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£",
        "‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏≤‡∏Å‡∏≤‡∏®",
        "‡∏†‡∏π‡πÄ‡∏Å‡πá‡∏ï‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£"
    ]
    
    for i, query in enumerate(test_queries, 1):
        print(f"\n{i}Ô∏è‚É£ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö: {query}")
        print("-" * 40)
        ask(query)
        
        if i < len(test_queries):
            input("\n‡∏Å‡∏î Enter ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ï‡πà‡∏≠...")

if __name__ == "__main__":
    test_improved_system()